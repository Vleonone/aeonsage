# ğŸ§  AeonSage Colab é…ç½®æŒ‡å—

## ğŸ¯ æ¦‚è¿°

æœ¬é…ç½®ä¸º AeonSage é¡¹ç›®åœ¨ Google Colab ç¯å¢ƒä¸­çš„å®Œæ•´éƒ¨ç½²æ–¹æ¡ˆï¼Œç‰¹åˆ«é›†æˆäº† Ollama ä»¥å®ç°é›¶Tokenæˆæœ¬çš„ AI æ¨ç†ï¼ŒåŒ…å«å¿«é€Ÿå¯åŠ¨å’Œå®Œæ•´é…ç½®ä¸¤ç§æ–¹å¼ã€‚

## ğŸš€ å¿«é€Ÿå¼€å§‹

### æ–¹æ³•ä¸€ï¼šä½¿ç”¨ Jupyter Notebook (æ¨è)

1. åœ¨ Colab ä¸­æ‰“å¼€ `colab/setup_colab.ipynb`
2. é€ä¸ªè¿è¡Œä»£ç å•å…ƒæ ¼
3. ç³»ç»Ÿä¼šè‡ªåŠ¨å®Œæˆç¯å¢ƒé…ç½®

### æ–¹æ³•äºŒï¼šä½¿ç”¨å¿«é€Ÿè„šæœ¬

```bash
# åœ¨ Colab å•å…ƒæ ¼ä¸­è¿è¡Œ
!bash colab/quick_setup.sh
```

## ğŸ“‹ å®Œæ•´é…ç½®æ­¥éª¤

### 1. ç³»ç»Ÿæ£€æŸ¥
```python
# æ£€æŸ¥ç³»ç»Ÿç¯å¢ƒ
import os
print(f"GPU å¯ç”¨: {'æ˜¯' if 'COLAB_GPU' in os.environ else 'å¦'}")
!node --version
!pnpm --version
```

### 2. å®‰è£…ä¾èµ–
```bash
# å®‰è£… Node.js 22
!curl -fsSL https://deb.nodesource.com/setup_22.x | bash -
!apt-get install -y nodejs

# å®‰è£… pnpm
!npm install -g pnpm@10.23.0
```

### 3. å…‹éš†å’Œæ„å»º
```bash
# å…‹éš†ä»“åº“
!git clone https://github.com/Vleonone/AeonsagePro.git aeonsage
%cd aeonsage

# å®‰è£…ä¾èµ–å¹¶æ„å»º
!pnpm install
!pnpm build
```

### 4. ç¯å¢ƒé…ç½®
```bash
# åˆ›å»ºç¯å¢ƒå˜é‡æ–‡ä»¶
cat > .env << EOF
NODE_ENV=development
AEONSAGE_PROFILE=colab
AEONSAGE_GATEWAY_PORT=18789
AEONSAGE_GATEWAY_BIND=0.0.0.0
EOF
```

## ğŸ® å¸¸ç”¨å‘½ä»¤

### å¯åŠ¨ç½‘å…³æœåŠ¡
```bash
# å¯åŠ¨å¼€å‘ç½‘å…³
!pnpm gateway:dev

# æˆ–è€…ä½¿ç”¨è‡ªå®šä¹‰ç«¯å£
!pnpm aeonsage gateway run --bind 0.0.0.0 --port 18789
```

### è¿è¡Œ CLI å‘½ä»¤
```bash
# æŸ¥çœ‹å¸®åŠ©
!pnpm aeonsage --help

# æ£€æŸ¥ç³»ç»ŸçŠ¶æ€
!pnpm aeonsage doctor

# è¿è¡Œä»£ç†
!pnpm aeonsage agent --message "ä½ å¥½ï¼ŒAeonSage!"
```

### æ‰§è¡Œæµ‹è¯•
```bash
# è¿è¡Œæµ‹è¯•å¥—ä»¶
!pnpm test

# è¿è¡Œç‰¹å®šæµ‹è¯•
!pnpm test -- src/commands/agent.test.ts
```

## ğŸ”§ é«˜çº§é…ç½®

### GPU æ”¯æŒ
```python
# æ£€æŸ¥å¹¶é…ç½® GPU
import os
if 'COLAB_GPU' in os.environ:
    print("âœ“ GPU å¯ç”¨")
    # å®‰è£… CUDA æ”¯æŒï¼ˆå¦‚éœ€è¦ï¼‰
    # !apt-get install -y cuda-toolkit
```

### Ollama é›†æˆ (é›¶Tokenæˆæœ¬)
```python
# Ollama è‡ªåŠ¨å®‰è£…å¹¶é…ç½®åœ¨ Colab ä¸­
!ollama --version

# éªŒè¯ Ollama æ¨¡å‹å¯ç”¨æ€§
!ollama list

# Ollama æä¾›ä½¿ç”¨æœ¬åœ°æ¨¡å‹çš„é›¶Tokenæˆæœ¬ AI æ¨ç†
print("ğŸ’¡ Ollama å®ç°äº†æœ¬åœ°æ¨¡å‹çš„é›¶Tokenæˆæœ¬ AI æ¨ç†")
```

### Google Drive é›†æˆ
```python
# æŒ‚è½½ Google Drive
from google.colab import drive
drive.mount('/content/drive')

# è®¾ç½®æŒä¹…åŒ–å­˜å‚¨
!mkdir -p /content/drive/MyDrive/aeonsage-data
```

### ç«¯å£è½¬å‘
```python
# è®¾ç½® ngrok éš§é“ï¼ˆç”¨äºå¤–éƒ¨è®¿é—®ç½‘å…³ï¼‰
!pip install pyngrok
from pyngrok import ngrok

# å¯åŠ¨éš§é“
public_url = ngrok.connect(18789)
print(f"ç½‘å…³å¯é€šè¿‡ {public_url} è®¿é—®")
```

## ğŸ› ï¸ æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

1. **å†…å­˜ä¸è¶³**
```bash
# æ¸…ç†ç¼“å­˜
!rm -rf ~/.pnpm-store
!pnpm store prune
```

2. **æ„å»ºå¤±è´¥**
```bash
# æ¸…æ´é‡æ–°æ„å»º
!pnpm clean:all
!pnpm install
!pnpm build
```

3. **æƒé™é—®é¢˜**
```bash
# ä¿®å¤æƒé™
!chmod +x colab/quick_setup.sh
```

### éªŒè¯å®‰è£…
```python
def verify_setup():
    checks = [
        ("Node.js", "node --version"),
        ("pnpm", "pnpm --version"),
        ("AeonSage", "pnpm aeonsage --version"),
    ]
    
    for name, cmd in checks:
        result = !{cmd} 2>/dev/null
        print(f"{'âœ“' if result else 'âœ—'} {name}: {result[0] if result else 'æœªå®‰è£…'}")

verify_setup()
```

## ğŸ“Š æ€§èƒ½ä¼˜åŒ–

### èµ„æºç›‘æ§
```python
# ç›‘æ§ç³»ç»Ÿèµ„æº
import psutil
import time

def monitor_resources():
    print("CPU ä½¿ç”¨ç‡:", psutil.cpu_percent())
    print("å†…å­˜ä½¿ç”¨:", psutil.virtual_memory().percent, "%")
    print("ç£ç›˜ä½¿ç”¨:", psutil.disk_usage('/').percent, "%")

monitor_resources()
```

### ç¼“å­˜ä¼˜åŒ–
```bash
# å¯ç”¨ pnpm å­˜å‚¨ä¼˜åŒ–
!pnpm config set store-dir ~/.pnpm-store
!pnpm config set virtual-store-dir ~/.pnpm-virtual
```

## ğŸ¤– AI é›†æˆç¤ºä¾‹

### åŸºç¡€ä»£ç†è°ƒç”¨
```python
# Python ä¸­è°ƒç”¨ AeonSage ä»£ç†
import subprocess
import json

def run_agent(message):
    result = subprocess.run([
        'pnpm', 'aeonsage', 'agent', 
        '--message', message,
        '--json'
    ], capture_output=True, text=True)
    
    return json.loads(result.stdout)

# ç¤ºä¾‹ä½¿ç”¨
response = run_agent("åˆ†æå½“å‰å¸‚åœºè¶‹åŠ¿")
print(json.dumps(response, indent=2, ensure_ascii=False))
```

### æ‰¹é‡å¤„ç†
```python
# æ‰¹é‡å¤„ç†æ¶ˆæ¯
messages = [
    "æ€»ç»“ä»Šå¤©çš„æ–°é—»è¦ç‚¹",
    "åˆ†ææ¯”ç‰¹å¸ä»·æ ¼èµ°åŠ¿",
    "ç”ŸæˆæŠ€æœ¯æ–‡æ¡£å¤§çº²"
]

for i, msg in enumerate(messages):
    print(f"å¤„ç†æ¶ˆæ¯ {i+1}: {msg}")
    result = run_agent(msg)
    print(f"ç»“æœ: {result.get('response', 'æ— å“åº”')}")
    print("-" * 50)
```

## ğŸ“š å‚è€ƒèµ„æº

- [AeonSage å®˜æ–¹æ–‡æ¡£](https://docs.aeonsage.org/)
- [Node.js 22 å®‰è£…æŒ‡å—](https://github.com/nodesource/distributions)
- [pnpm æ–‡æ¡£](https://pnpm.io/)
- [Google Colab å®˜æ–¹æ–‡æ¡£](https://colab.research.google.com/)

---
*æ­¤é…ç½®ç”± AeonSage CTO å›¢é˜Ÿç»´æŠ¤ï¼Œç¡®ä¿ä¸æœ€æ–°ç‰ˆæœ¬å…¼å®¹*